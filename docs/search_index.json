[["index.html", "Was denken Obikunden? Guten Tag!", " Was denken Obikunden? Sara Schiesberg 2023-09-05 Guten Tag! Guten Tag! Mein Name ist Sara Schiesberg und ich begeistere mich für Machine Learning im Allgemeinen und für Natural Langualge Processing (NLP) im Speziellen. Ich freue mich, Ihnen hier einen Einblick in meine Arbeit geben zu dürfen! Früher war es notwendig, unzählige Texte manuell zu durchforsten um deren Bedeutung zu erfassen. Heutzutage kann dies mit den Methoden der künstlichen Intelligenz wesentlich zeit- und kosteneffizienter geschehen. Zu diesem Zwecke zeige ich in dieser Arbeitsprobe eine Vorgehensweise mit einem Large Language Model (LLM). Konkret wird hier ein Fallbeispiel aus dem Bereich Customer Relationship Management umgesetzt. Darüber hinaus gibt es jedoch vielfältige andere Einsatzmöglichkeiten für die hier verwendeten Methoden. So kann man mit dieser Vorgehensweise die Meinungsdynamiken in Social-Media-Gruppen verfolgen und nach Akteuren suchen, die bestimmte ideologische Perspektiven vertreten. Im Bereich der Gesundheitsforschung können wir beispielsweise mithilfe dieser Technologien medizinische Daten effektiver analysieren und personalisierte Behandlungsansätze entwickeln Lassen Sie uns nun in die Praxis eintauchen und anhand eines konkreten Beispiels die Anwendung und Wirkung dieser spannenden Technologien genauer untersuchen. Herzlicher Gruß Sara Schiesberg "],["Abstract.html", "Abstract", " Abstract Die Beispielanalyse gliedert sich wie folgt: Setup und Daten: Ich verwende hier R-Markdown-Dateien, die neben Fließtext auch Codchunks und deren Output beinhalten. So können Sie mich und meine Arbeitsweise besser kennenlernen. Bei den Daten handelt es sich um Bewertungen und Reviews, die Obi-Kunden in den letzen Wochen auf www.trustedshops.de hinterlassen haben. Diese Daten werden mit Hilfe eines modernen Large Language Modells ausgewertet. Reviews und Bewertungen: In einem ersten Analyseschritt wird die Beziehung zwischen den Reviews und den Bewertungen mit konventionellen statistischen Methoden untersucht. Im Ergebnis lässt sich ein Zusammenhang zwischen dem Textumfang und den Bewertungen aufzeigen. So sind die unzufriedenen Kunden im Textmaterial überepräsentiert (Abb.3). Je niedriger die Kundenzufriedenheit ist, desto länger sind auch die Texte (Abb.4). Die Kundenreviews bilden als unstrukturierte Daten eine große sprachliche Viefalt ab. Diese Vielfalt wird durch eine Hauptkomponentenanalyse analysiert. Im Ergebnis zeigt dieses Verfahren des unüberwachten maschinellen Lernens, dass die semantische Varianz am besten durch die Kundenzufriedenheit erklärt werden kann (Abb.5). Aussagen und Themen: Eine Kundenreview kann Aussagen zu unterschiedlichen Themen beinhalten. Daher werden die Reviews für den zweiten Analyseschritt in unterschiedliche Aussagen aufgesplittet. Diese Aussagen werden anschließend durch verschiedene Methoden des maschinellen Lernen ausgewertet. Dabei handelt es sich zum einen um das unüberwachte, explorative Topic Modelling. Im Ergebnis zeigt dies ein für die gesamte Datenserie optimales Modell. So lassen sich die Themen aus der Kundenperspektive heraus entwickeln. In dem hiesigen Anwendungsfall werden beispielsweise für Kunden bedeutsamen Erlebnisse, wie das Warten oder eine schnelle und einfache Abwicklung als Cluster herauasgestellt (Abb. 6). Das Warten ist ein Aspekt, den Kunden in verschiedenen Phasen ihrer Customer Journey erleben können. Eine isolierte Betrachtung dieser Phasen ist für Entscheidungsträger typischerweise nützlich, da sich nur so ermitteln lässt, wo Verbesserungspotenzial besteht. Aufgrundessen beinhaltet diese Beispielanalyse auch eine konfirmatorische Themenanalyse. Dabei handelt es sich um eine semantische Suche, die hier als Zero-Shot-Learning implementiert ist. Dessen Ergebnisse deuten darauf hin, dass insbesondere die Liefergeschwindigkeit ein Thema ist, das die Kunden beschäftigt (siehe Abbildung 8). "],["SetupDaten.html", "Setup und Daten R-Markdown Daten Large Language Modell", " Setup und Daten R-Markdown Ich bin eine passioniert R-Userin. Derzeit spielt diese Programmiersprache insbesondere im Rahmen meiner Lehrtätigkeit an der Universität Koblenz eine große Rolle. Dort unterrichte ich Statistik mit R für Studenten der BioGeowissenschaften. In der Regel verwende ich ggplot, weil mich die Stringenz der “Grammar of Graphics” überzeugt. Neuerdings begeistere ich mich jedoch zunehmend für interaktiven Visualsierungen mit plotly. Diese Beispielanalyse basiert auf R-Markdown-Dateien, die mit Hilfe des Paketes als bookdown gerendert wurden. Ich schätze R-Markdown, weil die Kombination von Fließtext, Code und Output eine für andere gut nachvollziehbare Arbeitsweise und ein replizierbares Analyseergebnis gewährleistet. R-Markdown bietet vielfältigen Ausgabeformaten an. Ich entscheide mich hier für ein gitbook, weil ich so auch interaktive Visualsierungen mit plotly nutzen kann. Gemeinsam mit plotly lade ich weitere Pakete in meinen workspace. # Pakete laden library(bookdown) library(htmltools) library(httr) library(jsonlite) library(knitr) library(lsa) library(mclust) library(plotly) library(rvest) library(stringr) library(tidyverse) library(tokenizers) library(umap) library(viridisLite) library(xml2) # r-markdown setup knitr::opts_chunk$set(warning = FALSE, messages = FALSE) Daten Im Rahmen meiner derzeitigen Tätigkeit als Expert Data Science bei pressrelations arbeite ich mit Zeitungsartikeln und Social-Media-Posts. Hier geht es hingegen um Reviews, die Obikunden auf www.trustedshops.de hinterlassen haben. Typischerweise basieren Arbeitsproben auf Standartbeispieldatensätzen, wie wir sie von www.kaggle.com kennen. Ich habe mich hier bewusst gegen ein solches Standartbeispiel entschieden, um Ihnen ein möglichst realistisches Beispiel zu geben. Zu diesem Zwecke stelle ich mit dem Scraping eine Stichprobe zusammen, welche die ersten 50 Seiten einer nach dem Datum sortierten Abfrage enthält. Diese werden als anonymisierter Datensatz abgespeichert, der nur die analyserelevanten Variablen enthält. # Scraping url &lt;- &quot;https://www.trustedshops.de/bewertung/info_X8BD75374EABBAC74ABF111D4CBF94A65.html?sort=date&quot; daten &lt;- data.frame() for (nr in 1:50){ url_page &lt;- paste0(url, &quot;&amp;page=&quot;, nr) site &lt;- read_html(url_page) %&gt;% html_nodes(&quot;script[type=&#39;application/ld+json&#39;]&quot;) %&gt;% html_text() %&gt;% fromJSON() daten &lt;- bind_rows(daten, site$review) } # Tabelle aufräumen daten &lt;- daten %&gt;% unnest(reviewRating, names_sep = &quot;_&quot;) %&gt;% select(inLanguage, datePublished, reviewBody, reviewRating_ratingValue) %&gt;% rename(&quot;bewertung&quot; = reviewRating_ratingValue, &quot;datum&quot; = datePublished, &quot;review&quot; = reviewBody, &quot;sprache&quot; = inLanguage,) %&gt;% mutate(id = 1:n(), datum = as.Date(datum), bewertung = factor(bewertung, ordered = TRUE)) %&gt;% select(id, datum, bewertung, review, sprache) # Daten abspeichern save(daten, file = &quot;./daten_obi.RData&quot;) # Daten laden load(&quot;./daten_obi.RData&quot;) daten &lt;- daten %&gt;% mutate(review = str_replace_all(review, pattern = &quot;\\\\n|&lt;br&gt;|&lt;br/&gt;&quot;, replacement = &quot; &quot;), review = str_trim(review)) # Visualsierung: Tabelle plot_ly(type = &#39;table&#39;, columnwidth = c(30, 60, 60, 250, 50), header = list( values = c(names(daten) %&gt;% paste(&quot;&lt;b&gt;&quot;, ., &quot;&lt;/b&gt;&quot;, sep = &quot;&quot;)), fill = list(color = &quot;#31688EFF&quot;)), cells = list( values = rbind(t(as.matrix(unname(daten)))), align = c(&quot;center&quot;, &quot;center&quot;, &quot;center&quot;, &quot;left&quot;, &quot;center&quot;), fill = list(color = &quot;#D0E2EF&quot;))) Abb. 1 Die Rohdaten. Wenn Sie mit der Maus über die Abbildung fahren, erscheint oben rechts eine Bildlaufleiste. Mit dieser können Sie durch die Tabelle scrollen. Die Rohdaten umfassen insgesamt 1000 Bewertungen (Abb. 1). Die Bewertungen wurden in dem Zeitraum vom 2023-06-27 bis zum 2023-07-19 veröffentlicht. Bei den Bewertungen handelt es sich um Sterne, die Kunden an Obi vergeben haben. Ein einzelner Stern stellt das negativeste Feedback dar und die bestmögliche Bewertung sind 5 Sterne. In machen Fällen haben die Kunden keine Review zu ihrer Bewertung geschrieben. Die Sprache der Reviews wird ausnahmslos mit “DEU” angegeben. Large Language Modell Derzeit sind die Large Language Modells (LLMs) in aller Munde. Im Hinblick auf die Textanalyse sind diese Modelle insbesondere für eine Umwandlung der Texte in embeddings relevant. Für diese Beispielanalyse brauche ich embeddings, die man sowohl für die Hauptkomponentenanalyse, das Topic Modelling, wie auch für die semantische Suche nutzen kann. Diese Anforderung erfüllt “text-embedding-ada-002”, das über die API von Open-AI nutzbar ist. Vorab berechne ich die Kosten für das mit 0.0004 $ pro 1000 tokens bepreiste Model. # Kostenkalkulation costs &lt;- daten$review %&gt;% tokenize_words() %&gt;% lengths() %&gt;% sum()/1000*0.0004 Die Kosten sind mit 0.0042 $ sehr gut zu verschmerzen. Weiter gehts mit den Funktionsdefinitionen für die Request! # Funktionsdefinition: embeddings abfragen get_embeddings &lt;- function(texts){ response &lt;- POST(&quot;https://api.openai.com/v1/embeddings&quot;, add_headers(Authorization = paste(&quot;Bearer&quot;, api_key)), # api_key ist einzufügen body = list(model = &quot;text-embedding-ada-002&quot;, input = texts), encode = &quot;json&quot;) } # Funktionsdefinition: Matrix extrahieren get_embedding_matrix &lt;- function(response){ matrix_embeddings &lt;- response$content %&gt;% rawToChar() %&gt;% fromJSON() %&gt;% pluck(&quot;data&quot;, &quot;embedding&quot;) %&gt;% unlist() %&gt;% matrix(ncol = 1536, byrow = TRUE) return(matrix_embeddings) } "],["ReviesBewertungen.html", "Reviews und Bewertungen Textumfang und Bewertungen Varianz und Bewertungen", " Reviews und Bewertungen Im Folgenden steht der Zusammenhang zwischen den Reviews und den Bewertungen im Fokus des Interesses. Die Auseinandersetzung mit dem Textumfang der Reviews erfolgt am Beginn der Untersuchungen, weil damit eine quellenkritische Fragestellung einhergeht. So ist es interessant, ob in dem Textmaterial alle Kunden gleichermassen repräsentieren sind. Alternativ könnte hier auch eine Verzerrung durch die Kundenzufriedenheit vorliegen. Anschließend wird die semantische Varianz durch eine Hauptkomponentenanalyse ausgewertet. Dieses explorative Verfahren vermittelt typischerweise eine gute Vorstellung von den relevanten Wirkmechanismen im Datensatz. Um die Reviews im Zusammenhang mit den Bewertungen zu analysieren, werden vorab verschiedene Objekte definiert. # Anzahl Wörter pro Review daten &lt;- daten %&gt;% mutate(woerter = lengths(strsplit(review, &quot;\\\\s+&quot;))) # Nur die Fälle mit einer Review reviews &lt;- daten %&gt;% filter(woerter &gt; 0) # Zusammenfassende Angaben zu den Bewertungen bewertungen &lt;- daten %&gt;% group_by(bewertung) %&gt;% summarize( median_woerter = median(woerter), ges_n = n(), ohne_review_n = sum(woerter == 0), mit_review_n = sum(woerter != 0) ) %&gt;% mutate( ges_anteil = ges_n / sum(ges_n), mit_review_anteil = mit_review_n / sum(mit_review_n), ohne_review_anteil = ohne_review_n / sum(ohne_review_n) ) %&gt;% relocate(ohne_review_n, .before = ohne_review_anteil) %&gt;% relocate(ges_anteil, .after = ges_n) # Unterscheidet sich die Verteilung der Bewertungen ohne Review von der # Proportion, die man aufgrund der Bewertungen mit Review erwarten könnte? chi &lt;- chisq.test(bewertungen$ohne_review_n, p = bewertungen$mit_review_anteil) # Gibt es einen Zusammenhang zwischen der Bewertung und der Textlänge? cor &lt;- cor.test( as.numeric(reviews$bewertung), reviews$woerter, method = &quot;kendall&quot; ) Nun erzeuge ich ein Diagramm, das die Verteilung der unterschiedlichen Bewertungen zeigt. # Vorbereitung Visualisierung: Farbschema farbe &lt;- viridis(1) # Visualisierung: Kundenzufriedenheit insgesamt plot_ly(bewertungen, x = ~bewertung, y = ~ges_anteil, type = &quot;scatter&quot;, mode = &quot;lines+markers&quot;, line = list(color = farbe), hoverinfo = &quot;text&quot;, marker = list(size = 20, color = farbe), hovertext = ~paste(&quot;Sterne: &quot;, bewertung, &quot;&lt;br&gt;Anzahl: &quot;, ges_n, &quot;&lt;br&gt;Anteil: &quot;, round(ges_anteil * 100, 1), &quot;%&quot;)) %&gt;% layout( title = &quot;Kundenzufriedenheit insgesamt&quot;, title_pad = 50, xaxis = list(title = &quot;Sterne&quot;), yaxis = list(title = &quot;Anteil&quot;, tickformat = &quot;.0%&quot;, title_standoff = 50), showlegend = FALSE, margin = list(t = 50) ) Abb. 2 Die Häufigkeit der unterschiedlichen Bewertungen. Fahren Sie mit der Maus über das Diagramm um detaillierte Angaben zu einem Datenpunkt zu erhalten. Für OBI ist eine hohe Kundenzufriedenheit zu verzeichnen. So haben 67.5% der Kunden fünf Sterne vergeben (Abb. 2). Die Bewertung mit 2 Sterne sind mit nur 3% am seltensten vertreten. Textumfang und Bewertungen In insgesamt 28% der Fälle haben die Kunden keine Review zu ihrer Bewertung geschrieben. Es stellt sich die Frage, ob diese Kunden Obi anders bewerten als die Kunden, die auch eine Review geschrieben haben. # Vorbereitung für die Visualisierung: Farbschema farbe &lt;- viridis(3) # Visualisierung: Kundenzufriedenheit im Vergleich plot_ly(bewertungen) %&gt;% add_trace( x = ~bewertung, y = ~ohne_review_anteil, type = &quot;scatter&quot;, mode = &quot;lines+markers&quot;, name = &quot;ohne Review&quot;, marker = list(size = 20, color = farbe[2]), line = list(color = farbe[2]), hovertemplate = &quot;&lt;b&gt;ohne Review&lt;/b&gt;&lt;br&gt;Sterne: %{x}&lt;br&gt;Anzahl: %{marker.size}&lt;br&gt;Anteil: %{y:.1%}&quot; ) %&gt;% add_trace( x = ~bewertung, y = ~mit_review_anteil, type = &quot;scatter&quot;, mode = &quot;lines+markers&quot;, name = &quot;mit Review&quot;, marker = list(size = 20, color = farbe[3]), line = list(color = farbe[3]), hovertemplate = &quot;&lt;b&gt;mit Review&lt;/b&gt;&lt;br&gt;Sterne: %{x}&lt;br&gt;Anzahl: %{marker.size}&lt;br&gt;Anteil: %{y:.1%}&quot; ) %&gt;% layout( title = &quot;Kundenzufriedenheit im Vergleich&quot;, xaxis = list(title = &quot;Sterne&quot;), yaxis = list(title = &quot;Anteil&quot;, tickformat = &quot;.0%&quot;), showlegend = TRUE, legend = list(x = 0.1, y = 0.9, bordercolor = &quot;#E2E2E2&quot;, borderwidth = 2), margin = list(t = 50) ) Abb. 3 Vergleich zwischen Bewertungen mit und ohne Review. Ein Vergleich zwischen den Bewertungen mit und ohne Review zeigt, dass die unzufriedene Kunden ihre Kritik eher verbalisieren als die zufriedenen Kunden ihr Lob (Abb. 3). So sind bei den guten Bewertungen mit vier oder fünf Sternen die Kunden ohne Review mit einem höheren Anteil vertreten. Bei den schlechten Bewertungen verhält es sich jedoch umgekehrt. Das unterschiedliche Zufriedenheitsniveau der Kunden mit und ohne Review ist statistisch signifikant (χ² = 66.6, p = 1.21e-13). Ich möchte diese Überlegungen noch weiter vertiefen. Daher wird im Folgenden die Textlänge der Reviews differenziert nach dem Zufriedenheitsniveau ausgewertet. # Vorbereitung für die Visualsierung: Farbschema, Plotliste, Legendenvariable farbe &lt;- viridis(5) plots &lt;- list() reviews &lt;- reviews %&gt;% mutate(legende = case_when( bewertung == 1 ~ paste(bewertung, &quot;Stern&quot;), bewertung &gt; 1 ~ paste(bewertung, &quot;Sterne&quot;), TRUE ~ as.character(bewertung))) # Schleife: Densityplot mit Textlängen für jede Bewertung for (row in 1:nrow(bewertungen)) { d &lt;- density(reviews %&gt;% filter(bewertung == row) %&gt;% pull(woerter)) nearest_index &lt;- which.min(abs(d$x - bewertungen[[row, &quot;median_woerter&quot;]])) # für Höhe der Medianlinien plots[[row]] &lt;- plot_ly() %&gt;% add_lines(x = d$x, y = d$y, name = paste(row, &quot;Stern&quot;), fill = &#39;tozeroy&#39;, hoverinfo = &quot;none&quot;, line = list(color = farbe[row]), fillcolor = adjustcolor(farbe[row], alpha.f = 0.5)) %&gt;% add_trace(x = c(bewertungen[[row, &quot;median_woerter&quot;]], bewertungen[[row, &quot;median_woerter&quot;]]), y = c(0, d$y[nearest_index]), type = &quot;scatter&quot;, mode = &quot;lines&quot;, line = list(color = farbe[row]), hoverinfo = &quot;text&quot;, hovertext = paste(&quot;Sterne:&quot;, row, &quot;&lt;br&gt;Median:&quot;, bewertungen[row, &quot;median_woerter&quot;])) %&gt;% layout(annotations = list(x = 170 , y = max(d$y), text = paste(&quot;&lt;b&gt;&quot;, sort(unique(reviews$legende))[row], &quot;&lt;/b&gt;&quot;), showarrow = FALSE, colour = farbe[row])) } # Zusammenfügen: Densityplots für jede Bewertungen subplot(rev(plots), nrows = 5, shareY = TRUE, shareX = TRUE) %&gt;% layout(title = &quot;Textlängen der verschiedenen Bewertungen&quot;, xaxis = list(title = &quot;Anzahl Wörter&quot;, zeroline = FALSE), yaxis = list(title = &quot;Density&quot;), showlegend = FALSE, margin = list(t = 50) ) Abb. 4 Densityplot zur Anzahl der Wörter differenziert nach der Bewertung. Die vertikalen Linien geben die Mediane für die entsprechenden Stichproben an. Es gibt Reviews, die lediglich ein Wort beinhalten. Maximal sind jedoch bis zu 171 Wörter möglich. Je negativer eine Bewertung ist, desto länger ist typischerweise der Text. Dieser Zusammenhang ist in Abb. 4 zu erkennen. Bei den sehr guten Bewertungen mit 5 Sternen schreiben die Kunden im Durchschnitt lediglich 4 Wörter. Kunden, die nur einen Stern vergeben haben, schreiben hingegen im Durchschnitt 23 Wörter. Unter diesen besonders schlechten Bewertungen sind auffallend viele lange Texte mit mehr mehr als 100 Wörtern zu finden. Insgesamt betrachtet zeichnet sich hier ein statistisch relevanter Zusammenhang zwischen der Textlänge und der Zufriedenheit ab (τ = -0.35, p = 4.92e-33). Abschließend lässt es sich festhalten, dass die Kundenreviews keine repräsentative Stichprobe darstellen, wie wir sie aus der Marktforschung kennen. Anstelle hören wir durch eine Analyse der Kundenreviews insbesondere einer ganz spezifischen Gruppe zu: den unzufriedenen Kunden. Varianz und Bewertungen Im Folgenden frage ich die embeddings von einem großen Sprachmodell ab. Diese numerischen Repräsentationen der Reviews stellen dann den Input für eine Hauptkomponentenanalyse (PCA) dar. Dabei handelt es sich um einen ergebnismächtigen Algorithmus aus dem Bereich des unüberwachten maschinellen Lernens, der Muster in großen Datensammlungen aufzeigen kann. # Request embeddings response_embeddings &lt;- get_embeddings(reviews$Review) # Abspeichern save(response_embeddings, file = &quot;./response_embeddings_reviews_obi.RData&quot;) # Daten laden und Matrix extrahieren load(&quot;./response_embeddings_reviews_obi.RData&quot;) matrix_embeddings_reviews &lt;- get_embedding_matrix(response_embeddings) # Dimensionsreduktion (PCA) pca &lt;- prcomp(matrix_embeddings_reviews) kumulative_varianz &lt;- cumsum(pca$sdev^2 / sum(pca$sdev^2)) # Ergebnisse an Dataframe anhängen reviews &lt;- reviews %&gt;% mutate(pc1 = pca$x[, 1], pc2 = pca$x[, 2]) # Vorbereitung für die Visualsierung: Legendenvariable levels &lt;- unique(reviews$legende) %&gt;% sort(decreasing = TRUE) reviews &lt;- reviews %&gt;% mutate(legende = factor(legende, levels = levels)) # Visualsierung: Kundenreviews im semantischen Ähnlichkeitsraum plot_ly(data = reviews, x = ~pc1, y = ~pc2, color = ~legende, colors = rev(viridis(5)), type = &quot;scatter&quot;, mode = &quot;markers&quot;, hoverinfo = &quot;text&quot;, text = ~str_wrap(review, width = 50)) %&gt;% layout(title = &quot;Kundenreviews im semantischen Ähnlichkeitsraum&quot;, margin = list(t = 50), legend = list(x = 0.02, y = 0.02, bordercolor = &quot;#E2E2E2&quot;, borderwidth = 2)) Abb. 5 Die Kundenreviews im Ähnlichkeitsraum der PCA. Wenn Sie mit der Maus über die Signaturen fahren, erscheinen die entsprechenden Texte der Reviews. Mit Hilfe einer PCA können die Kundenreviews im semantischen Ähnlichkeitsraum abgebildet werden (Abb.5). In diesem Raum liegen Reviews mit einem ähnlichen Text nahe beeinder. Reviews mit einer abweichenden Semantik befinden sich hingegen weiter voneinander entfernt. Der semantische Ähnlichkeitsraum wird durch die ersten beiden Hauptkomponenten definiert, die insgesamt 18 % der Varianz erklären. In Anbetracht der Tatsache, dass die PCA 725 Achsen extrahiert hat, ist dies ein ausgesprochen gutes Ergebnis. Mich persönlich fasziniert insbesondere das unüberwachte Lernen, weil ich damit Variablen herauskitzeln kann, die in dem Datensatz so eigentlich garnicht vorhanden sind. In dem hiesigen Anwendungsfall basiert die Berechnung auf den embeddings, wohingegen die Bewertungen unberücksichtigt bleiben. Dennoch bildet die PCA dieses Merkmal ab! So sind die mit einem Stern assoziierten Reviews im Ähnlichkeitsraum oben links angeordnet. Je weiter man sich im Diagramm (Abb.5) nach unten oder nach links bewegt, desto besser werden auch die mit den Reviews einhergehenden Bewertungen. Ich habe schon viele Textkorpora auf die hier vorgestellte Art und Weise ausgewertet. Oftmals kann man in den Ähnlichkeitsräumen der PCA Cluster erkennen, die thematische Schwerpunkte repräsentieren. Interessanterweise ist dies bei den Kundenreviews nicht der Fall. So wird die semantische Varianz hier in erster Linie durch die Kundenzufriedenheit bestimmt. Das könnte daran liegen, dass die Kunden gerade in den mit einer schlechten Bewertung einhergehenden längeren Reviews verschiedene Themen ansprechen. Aufgrund dieser Problematik werden die Revievs im Folgenden in einzelne Aussagen aufgesplittet. "],["AussagenThemen.html", "Aussagen und Themen Topic Modelling Semantische Suche", " Aussagen und Themen Man kann LLMs auch nutzen um Themen in großen Textcorpora zu identifizieren. Für diesen Zweck ist es in der Regel sinnvoll die Texte in kleinere Einheiten aufzusplitten. So sind die Modelle typischerweise trennschärfer, wenn die zu analysierenden Texte nur einzelne Aspekte ansprechen. Im Folgenden splitte ich die Reviews mit einem regelbasierten Ansatz in unterschiedliche Aussagen auf. # Reviews in einzelne Aussagen splitten aussagen &lt;- reviews %&gt;% select(id, bewertung, review) %&gt;% mutate(aussage = str_split(review, &quot;(?&lt;=[[:alnum:]]{3})\\\\.|\\\\!|\\\\?|\\\\•&quot;)) %&gt;% # mindestens drei alphanumerische Zeichen vor dem Punkt, Ausrufezeichen, Fragezeichen oder Bullet-Punkt unnest(aussage) %&gt;% mutate(aussage = str_trim(aussage), aussage = tolower(aussage)) %&gt;% filter(grepl(&quot;\\\\b\\\\w+\\\\b|\\\\b\\\\d+\\\\b&quot;, aussage, perl = TRUE)) # mindestens 2 durch eine Leerstelle getrennte Wörter und Zahlen Hier kommen zwei verschiedene Techniken zum Einsatz. Das ist zum einen die explorative Technik des Topic Modellings. Bei dieser Methodik geben die Analysten keine Themen vor, sondern leiten diese ganz ergebnisoffen aus den Daten ab. Auf diese Art und Weise offenbart ein Topic Modell, was wirklich in den Daten steckt. Manchmal stellen Stakeholder sehr spezifische Fragen, die sich nicht mit den Clustern eines Topic Models beantworten lassen. Aufgrund dessen kommt hier auch eine hochmoderne Semantische Suche zum Einsatz. Mit einer solchen konfirmatischen Vorgehensweise wird die Präsenz eines vorab definierten Konzeptes in den Daten überprüft. In dem hiesigen Anwendungsfalls sind dies positive und negative Statements zu einzelnen Themen. Topic Modelling Nur allzuoft werden Themen in großen Textcorpora mit Hilfe einfacher Suchabfragen ermittelt. Auf diese Art und Weise verkennen Analysten, worum es in den Texten wirklich geht, weil sie nur jene Themen herausstellen, die sie eh schon im Kopf haben. Für diese Problematik stellt das Topic Modelling als explorative Technik einen Lösungsansatz dar. Früher habe ich Themen mit Latenten Dirichlet Allokationen (LDA) modelliert. Ich erinnere mich noch gut daran, wie ich das erste Mal ein neuronales Topic Modelling durchgeführt habe, weil mich die Steigerung der Ergebnisqualität so beeindruckt hat. Die LDA basiert im Prinzip auf einem bag-of-words Modell in dem der Wortkontext verloren ist. Dahingegen liegen dem neuronalen Topic Modelling die embeddings eines LLM zu Grunde. Im Laufe meiner Karriere habe ich für diesen Zweck insbesondere das Python-Paket BERTopic genutzt. Für die hier voliegende Beispielanalyse mit R verwende ich ein einfache, effektive Vorgehensweise. In deren Rahmen werden die embeddings für die Aussagen durch eine Dimensionsreduktion ausgewertet. Dabei entscheide ich mich für den umap()-Algorithmus, weil dieser eine auf zwei Dimensionen beschränkte Repräsentation erzeugen kann. Die entsprechenden Koordinaten werden dann durch einen Clusteralgorithmus ausgewertet. Zu diesem Zwecke verwende ich mclust(), weil dieser Algorithmus auch Wahrscheinlichkeitswerte für die Zugehörigkeit zu einem Cluster ausgibt. Das hat sich in meiner Arbeit mit Social-Media-Posts als nützlich erwiesen, weil diese viel noise enthalten können. Die Modellierung wird so ausgeführt, dass die optimale Anzahl der Cluster automatisch bestimmt wird. Dann finden nur Aussagen Berücksichtigung, die hochwahrscheinlich für einen Cluster sind. # Request embeddings response_aussagen &lt;- get_embeddings(aussagen$aussage) # Daten speichern save(response_aussagen, file = &quot;./response_embeddings_aussagen_obi.RData&quot;) # Daten laden und Matrix extrahieren load(&quot;./response_embeddings_aussagen_obi.RData&quot;) matrix_embeddings_aussagen &lt;- get_embedding_matrix(response_aussagen) # Dimensionsreduktion und Clustern umap_aussagen &lt;- umap(matrix_embeddings_aussagen, random_state = 333) # Seed für die Reproduzierbarkeit des stochastischen Modells cluster &lt;- Mclust(umap_aussagen$layout) anz_cluster &lt;- length(unique(cluster$classification)) # Ergebnisse an Dataframe anhängen aussagen &lt;- aussagen %&gt;% mutate( umap1 = umap_aussagen$layout[, 1], umap2 = umap_aussagen$layout[, 2], cluster = case_when( cluster$uncertainty &gt; 0.1 ~ 0, # d.h. 95% p für einen Cluster TRUE ~ cluster$classification)) %&gt;% group_by(cluster) %&gt;% mutate(anz = n()) %&gt;% ungroup() %&gt;% as.data.frame() # Themen benennen aussagen &lt;- aussagen %&gt;% mutate( thema = case_when( cluster == 1 ~ paste(&quot;einfache, umkomplizierte Abwicklung, &lt;br&gt;n =&quot;, anz), cluster == 2 ~ paste(&quot;Kritik an der Ware, &lt;br&gt;n =&quot;, anz), cluster == 3 ~ paste(&quot;positives Fazit zum Einkauserlebnis, &lt;br&gt;n =&quot;, anz), cluster == 4 ~ paste(&quot;positive Einkaufsbewertung, &lt;br&gt;n =&quot;, anz), cluster == 5 ~ paste(&quot;Obi, &lt;br&gt;n =&quot;, anz), cluster == 6 ~ paste(&quot;Warten, &lt;br&gt;n =&quot;, anz), cluster == 7 ~ paste(&quot;Kundenservice, &lt;br&gt;n =&quot;, anz), cluster == 8 ~ paste(&quot;schnell und günstig, &lt;br&gt;n =&quot;, anz), cluster == 9 ~ paste(&quot;schnelle Lieferung, &lt;br&gt;n =&quot;, anz), TRUE ~ &quot;x&quot; ) ) # Vorbereitung Visualisierung: Farbschema, Legendenvariable farben &lt;- c(viridis(anz_cluster), &quot;#E2E2E2&quot;) levels &lt;- aussagen %&gt;% arrange(anz) %&gt;% pull(thema) %&gt;% unique() aussagen &lt;- aussagen %&gt;% mutate(thema = factor(thema, levels = levels, ordered = TRUE)) # Visualisierung: Semantische Gruppen plot_ly() %&gt;% add_trace(data = filter(aussagen, cluster == 0), x = ~umap1, y = ~umap2, color = ~thema, colors = farben, type = &quot;scatter&quot;, mode = &quot;markers&quot;, hoverinfo = &quot;text&quot;, text = ~paste(&quot;Aussage: &quot;, str_wrap(aussage, width = 50)), showlegend = FALSE) %&gt;% add_trace(data = filter(aussagen, cluster != 0), x = ~umap1, y = ~umap2, color = ~thema, colors = viridis(10), type = &quot;scatter&quot;, mode = &quot;markers&quot;, hoverinfo = &quot;text&quot;, text = ~paste(&quot;Aussage: &quot;, str_wrap(aussage, width = 50), &quot;&lt;br&gt;Label: &quot;, thema), showlegend = TRUE) %&gt;% layout(title = &quot;Semantische Gruppen von Kundenaussagen&quot;, legend = list(orientation = &#39;h&#39;, y = -0.2), margin = list(t = 50), showlegend = TRUE) Abb. 6 Semantische Gruppen von Kundenaussagen. Wenn Sie mit der Maus über die Signaturen fahren, erscheint die entsprechende Aussagen sowie das Label und die Anzahl der Aussagen pro Cluster. Das Topic Modelling zeigt Cluster, die semantisch ähnliche Aussagen beinhalten. In dem hiesigen Anwendungsfall betreffen die beiden größten Themenkomplexe zwei ganz unterschiedliche Kundenerlebnisse. Das ist zum eine die einfache, umkomplizierte Abwicklung und zum anderen das Warten. Unter diesen beiden Gesichtspunkten beschreiben Kunden verschiedene Momente der Customer Journey. Diese reichen von der Bestellung im Online-Shop, dem Austausch von E-Mails, der Bezahlung bis hin zur Lieferung der Waren. In Abb. 6 ist links oben eine Gruppe von Statements zu finden, die eine postive Einkaufsbewertung zum Ausdruck bringen. Besonders häufig ist hier die knappe Formulierung “Alles gut”. Nahe bei dieser Gruppe befindet sich ein Cluster von Aussagen, die ein positives Fazit zum Einkaufserlebnis geben. In dieser Gruppe kommen die Empfindungen der Käufer durch Dankes-, Zufriedenheits- und Loyaltitätsbekundungen wesentlich stärker zum Ausdruck. Einen weiteren Themenblock stellt die Kritik an der Ware dar. Hierunter fallen beispielsweise Aussagen zur Warenqualität, Probleme beim Aufbau sowie Beschädigungen durch den Versand. Da die Kunden Obi nur selten direkt erwähnen, repräsentieren die Statements mit einer direkten Unternehmennung eine distinkte Gruppe im Themenmodell. Die Aussagen über den Kundenservice sind ganz überwiegend positiv konnotiert. In einem links daneben liegenden Cluster heben die Kunden insbesondere die Apekte schnell und günstig hervor. Nahe bei dieser Gruppe liegen die Statements zur schnellen Lieferung, die im wesentlichen aus eben dieser Wortkombination bestehen. Aufgrund dieses immer gleichlautenden wordings erkennt die KI hier eine eigenständige Gruppe. Bei einer Inspektion von Abb. 6 mit der Hooverfunktion, kann man innnerhalb eines jeden Clusters Textpassagen antreffen, die hier eigentlich gar nicht so gut reinpassen. Dabei handelt es sich oftmals um Wörter, die keine Aussage im eigentlichen Sinne repräsentieren. Diese Wörter sind die Konsequenz eines Aufsplittens der Reviews durch einen regelblasierten Ansatz. Eine Verbesserung der Ergebnisqualität ist potentiell möglich, wenn man diesen Arbeitsschritt mit einem Verfahren des maschinellen Lernens durchführt. Da man für diesen Zweck Trainingsdaten benötigt, sprengt diese Vorgehensweise jedoch den Rahmen der vorliegenden Arbeitssprobe. Semantische Suche Im Zusammenhang mit den LLMs fasziniert mich insbesondere die Zero-Shot-Klassifikation, weil man für diese Vorgehensweise keine Trainingsdaten braucht. Solche Trainingsdaten werden oftmals von einzelnen Analysten erzeugt, die alle Texte lesen und mit Labeln versehen. Im Laufe meiner Karriere habe ich viele Studenten bei dieser zeitintensiven Aufgabe betreut. Regelbasierte Ansätze, mit denen man bestimmte Wörter abfragt, gelten als kostengünstige Alternative für die Textklassifikation. Allerdings verkennt man mit einer solchen lexikalischen Suche oftmals die eigentliche Bedeutung des Textes. Dahingegen berücksichtigt eine semantische Suche die Bedeutung der Wörter. Auf diese Art und Weise ermöglichen LLMs eine sowohl kostengüntige als auch qualitativ hochwertige Textklassifikation. Mit einer semantischen Suche kann ich den unstrukturierten Datenbestand der Kundenreviews gezielt nach spezifischen Aussagen durchforsten. Auf diese Art und Weise lässt es sich festellen, was die Kunden an ihrem Einkaufserlebnis besonders schlecht oder aber gut finden. So können Unternehmen handlungsrelevante insights generieren. Im Folgenden formuliere ich idealtypische Beispiele für verschiedene Aussagetypen. Diese Beispiele repräsentieren unterschiedliche Kundenerlebnisse. Wenn ein Kunde von einem solchen Erlebnis erzählt, weist diese Aussage eine hohe Ähnlichkeit zu dem entsprechenden Beispiel auf. Aufgrundessen bestimme ich anschließend für jedes Beispiel die Ähnlichkeit zu allen Kundenaussagen. Diese Ähnlichkeit ist hier mathematisch als Kosinus-Distanz zwischen den entsprehenden embeddings definiert. # Beispiele formulieren beispiele &lt;- data.frame( beispiel = c(&quot;die mitarbeiter sind freundlich. ich finde das personal zuvorkommend&quot;, &quot;die mitarbeiter unfreundlich. ich finde das personal unhöflich&quot;, &quot;die lieferung war schnell. ich habe die ware rechtzeitig erhalten&quot;, &quot;die lieferung war langsam. ich habe lange auf die die ware gewartet&quot;, &quot;die produkte sind preiswert. ich habe einen günstigen preis bezahlt&quot;, &quot;die produkte sind kostspielig. ich habe einen zu teueren preis bezahlt.&quot;, &quot;der online-shop ist übersichlich. ich habe die produkte auf der website leicht gefunden&quot;, &quot;der online-shop unübersichtlich. Ich habe schwierigkeiten gehabt, die produkte auf der website zu finden&quot;, &quot;die produkte sind von hoher qualität. ich finde die warenbeschaffenheit gut&quot;, &quot;die sind von niedriger qualität. ich finde die warenbeschaffenheit schlecht&quot;), aussagetyp = c(&quot;freundliche Mitarbeiter&quot;, &quot;unfreundliche Mitarbeiter&quot;, &quot;schnelle Lieferung&quot;, &quot;verzögerte Lieferung&quot;, &quot;günstige Preise&quot;, &quot;zu teure Preise&quot;, &quot;übersichtlicher Online-Shop&quot;, &quot;unübersichtlicher Online-Shop&quot;, &quot;gute Warenqualität&quot;, &quot;schlechte Warenqualität&quot;), thema = c(&quot;Freundlichkeit der Mitarbeiter&quot;, &quot;Freundlichkeit der Mitarbeiter&quot;, &quot;Geschwindigkeit der Lieferung&quot;, &quot;Geschwindigkeit der Lieferung&quot;, &quot;Preise&quot;, &quot;Preise&quot;, &quot;Übersichtlichkeit des Online-Shops&quot;, &quot;Übersichtlichkeit des Online-Shops&quot;, &quot;Warenqualität&quot;, &quot;Warenqualität&quot;), sentiment = c(&quot;positiv&quot;, &quot;negativ&quot;, &quot;positiv&quot;, &quot;negativ&quot;, &quot;positiv&quot;, &quot;negativ&quot;, &quot;positiv&quot;, &quot;negativ&quot;, &quot;positiv&quot;, &quot;negativ&quot;) ) Nun werden die embeddings für die Beispiele bestimmt. # Request embeddings response_embeddings_beispiele &lt;- get_embeddings(beispiele$beispiel) # Daten abspeichern save(response_embeddings_beispiele, file = &quot;./response_embeddings_beispiele_obi.RData&quot;) Jetzt erfolgt die Distanzberechnung zwischen den embeddings für die Beispiele und den embeddings der Kundenaussagen. # Embeddings laden und Matrix extrahieren load(file = &quot;./response_embeddings_beispiele_obi.RData&quot;) matrix_embeddings_beispiele &lt;- get_embedding_matrix(response_embeddings_beispiele) # Vorbereitung für die Distanzberechnung: Vektoren initialisieren thema &lt;- character() typ &lt;- character() sent &lt;- character() bsp &lt;- character() aus &lt;- character() kos &lt;- numeric() # Distanzberechnung mit verschachtelter Schleife for (bei_row in 1:nrow(matrix_embeddings_beispiele)) { #für jedes Beispiel for (aus_row in 1:nrow(matrix_embeddings_aussagen)) { # für jede Aussage thema &lt;- append(thema, beispiele[bei_row, &quot;thema&quot;]) typ &lt;- append(typ, beispiele[bei_row, &quot;aussagetyp&quot;]) sent &lt;- append(sent, beispiele[bei_row, &quot;sentiment&quot;]) bsp &lt;- append(bsp, beispiele[bei_row, &quot;beispiel&quot;]) aus &lt;- append(aus, aussagen[aus_row, &quot;aussage&quot;]) kos &lt;- append(kos, cosine(matrix_embeddings_beispiele[bei_row,], as.numeric(matrix_embeddings_aussagen[aus_row,]))) } } # Dataframe erstellen similarity &lt;- data.frame(thema = thema, aussagetyp = typ, sentiment = sent, beispiel = bsp, aussage = aus, kosinus = kos) Ich möchte eine Visualsierung erzeugen, die sowohl relevante Datenstrukturen aufzeigt als auch eine Inspektion des Einzelfalls zulässt. Aufgrundessen entscheide mich hier für eine Visualsierung durch einen Jitter-Plot. # Vorbereitung Visualisierung: Objekte initialsieren und definieren plots &lt;- list() farben &lt;- viridis(length(unique(beispiele$beispiel))) schwelle &lt;- 0.875 # Visualsierung: Jitterplots für positive und negative Statements for (row in 1:2) { plots[[row]] &lt;- plot_ly( data = similarity %&gt;% filter(sentiment == c(&quot;positiv&quot;, &quot;negativ&quot;)[row])) %&gt;% add_trace( y = ~kosinus, x = ~jitter(as.numeric(factor(thema))), type = &quot;scatter&quot;, mode = &quot;markers&quot;, color = ~thema, colors = farben, marker = list(size = 3, opacity = 0.7), hoverinfo = &quot;text&quot;, text = ~paste(&quot;&lt;br&gt;Aussage:&quot;, str_wrap(aussage, width = 30), &quot;&lt;br&gt;Aussagetyp:&quot;, aussagetyp, &quot;&lt;br&gt;Beispiel: &quot;, beispiel, &quot;&lt;br&gt;Kosinus-Distanz:&quot;, round(kosinus, 2))) %&gt;% add_segments(x = 0, xend = nrow(beispiele), y = schwelle, yend = schwelle, line = list(color = &quot;black&quot;, width = 2)) %&gt;% layout(annotations = list(x = 5.7, y = 0.95, text = paste(&quot;&lt;b&gt;&quot;, c(&quot;positiv&quot;, &quot;negativ&quot;)[row], &quot;&lt;b&gt;&quot;, sep = &quot;&quot;), showarrow = FALSE, font = list(size = 12)), xaxis = list(range = c(0, 6), tickvals = 1:5, title = &quot;Aussagetyp&quot;, ticktext = ~str_wrap(unique(aussagetyp), 13)), yaxis = list(range = c(0.7, 1), title = &quot;Kosinus-Distanz&quot;), showlegend = FALSE) } # Zusammenfügen der plots subplot(plots, nrows = 2, shareY = TRUE, shareX = FALSE, margin = 0.05) %&gt;% layout(margin = list(t = 50), title = &quot;Die Ähnlichkeit zwischen den Kundenaussagen und den Beispielstatements&quot;) Abb. 7 Jitterplots zur Ähnlichkeit zwischen den Kundenaussagen und den Beispielstatements für verschiedene Aussaagetypen. In Abb. 7 repräsentiert jeder Datenpunkt eine Kundenaussage. Je höher ein Datenpunkt liegt, desto ähnlicher ist diese Aussage dem entsprechenden Beispielstatement für einen bestimmten Aussagetyp. Generell fallen die Kosinus-Distanzen hier mit einem Wertespektrum von 0.71 bis 0.96 sehr hoch aus. Das ist nicht verwunderlich, da auch die Beispielstatements als Kundenaussagen formuliert wurden. Besonders hohe Kosinus-Distanzen zeigen sich für den Aussagetyp “schnelle Lieferung”. Das harmoniert sehr gut mit der Tatsache dass diese Statements auch im neuronalen Topic Model ein eigenständiges Thema repräsentieren (Abb. 6). Geringere Kosinus-Distanzen sind hingegen für Aussagen zu “unfreundlichen Mitarbeitern” oder aber “teuren Preisen” zu verzeichnen. Solche Statements sind auch im Topic Model nicht deutlich in Erscheinung getreten. Da eine semantischen Suche die Bedeutung einer Aussage erfasst, hat ein Statement mit den Wörtern „sendung kam früher als erwartet“ eine große Ähnlichkeit zu der Beispielaussage „die lieferung war schnell. ich habe die ware rechtzeitig erhalten“. Mit einer bloßen lexikalischen Suche hätte man diese Ähnlichkeit niemals erfassen können, weil die beiden Aussagen unterschiedliche Wörter beinhalten. Bei einer semantischen Suche liegt die Kunst eigentlich darin, wie man das Beispiel formuliert. In einem ersten Anlauf hatte ich das Beispiel für den Aussagetyp verzögerte Lieferung mit den Wörtern „die lieferung war unpünktlich“ formuliert. Die entsprechenden Beispielstatements waren dann besonders ähnlich zu Kundenaussagen, die eine besonders rasche Zustellung loben, die früher als angekündigt erfolgte. Das ist aber nicht wirklich im Sinne der hier vorgestellten Analyse… Da Sprache ein nuanciertes und facettenreiches System ist, gefällt es mir eigentlich ganz gut mit einem Modell zu arbeiten das viele Abstufungen zulässt. In der Praxis ist es jedoch zielführender die Kundenaussagen einer einzelnen Kategorie zuzuweisen. Denn nur so kann man die für Stakeholder relevante Frage beantworten, wie oft ein bestimmter Aussagetyp vorkommt. Im Folgenden werden Kundenaussagen deren Kosinus-Distanz zu einem bestimmten Beispielstatement höher als 0.875 ist dem entsprechenden Aussagetypen zugeordent. Dieser arbiträre Schwellenwert wurde nach einer visuellen Inspektion von Abb. 7 gewählt. Die unterschiedlichen Aussagetypen repräsentieren für ein Thema genau eine positive und eine negative Merkmalsausprägung. Oftmals werden solche Sentimentsausprägungen durch gestapelte Balkendiagramme dargestellt. Diese Diagramme visualsieren ein prozentuales Verhältnis, das bei kleinen Fallzahlen keine Aussagekraft besitzen. Diese Problematik wird hier durch die Verwendung eines Marimekko-Charts umgangen. So zeigt bei dieser Darstellungsform die Balkenbreite den Stichprobenumfang an. # Vorbereitung Visualisierung: nach Themen zusammenfassende Tabelle thema &lt;- similarity %&gt;% filter(kosinus &gt; schwelle) %&gt;% count(sentiment, thema) %&gt;% pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %&gt;% mutate(n = positiv + negativ, proz_positiv = positiv/n, proz_negativ = negativ/n, breite = n/sum(n)) %&gt;% # Breite der Säulen arrange(proz_negativ) %&gt;% mutate(position = cumsum(breite)) %&gt;% mutate(position = ifelse(row_number() == 1, position/2, (lag(position) + position) / 2+(row_number() - 1) * 0.05)) # Position der Säulen mit einem Abstand von 0.05 # Vorbereitung Visualisierung: Farbschema farben &lt;- viridis(2) # Visualisierung Marimekko-Chart Proportionen pro Thema plot_ly(data = thema, y = ~position, orientation = &quot;h&quot;) %&gt;% add_trace(x = ~proz_negativ, name = &quot;negativ&quot;, width = ~breite, type = &quot;bar&quot;, marker = list(color = farben[1]), textposition = &quot;none&quot;, hoverinfo = &quot;text&quot;, text = ~paste(&quot;&lt;br&gt;Anzahl: &quot;, negativ, &quot;&lt;br&gt;Prozent: &quot;, round(proz_negativ*100, 0), &quot;%&quot;, sep = &quot;&quot;)) %&gt;% add_trace(x = ~proz_positiv, name = &quot;positiv&quot;, width = ~breite, type = &quot;bar&quot;, marker = list(color = farben[2]), textposition = &quot;none&quot;, hoverinfo = &quot;text&quot;, text = ~paste(&quot;&lt;br&gt;Anzahl: &quot;, positiv, &quot;&lt;br&gt;Prozent: &quot;, round(proz_positiv*100, 0), &quot;%&quot;, sep = &quot;&quot;)) %&gt;% layout(barmode = &#39;stack&#39;, title = &quot;Verhältnis zwischen positiven und negativen Aussagen&quot;, yaxis = list(title = &quot;&quot;, tickvals = thema$position, ticktext = thema$thema), xaxis = list(title = &quot;Anteil&quot;, tickformat = &quot;.0%&quot;), margin = list(t = 50)) Abb. 8 Das prozentuale Verhältnis zwischen positiven und negativen Aussagen zu einem spezifischen Thema. Die Breite der Balken ist proportional zur Anzahl der Treffer. Im Ergebnis zeigt sich für die Geschwindigkeit der Lieferung eine größere Datenserie (Abb. 8). Dementsprechend scheint dies ein Aspekt zu sein, der die Kunden besonders stark bewegt. Unter den Statements zur Geschwindigkeit der Lieferung gibt es mehr negative Aussagen als zu all den anderen hier untersuchten Themen. Allerdings ist für diese Themen die Gesamtanzahl der Aussagen auch sehr viel niedriger. Aufgrund dessen gehe ich davon aus, dass diese Themen die Kunden weniger stark beschäftigen. Für eine tiefergreifendes Verständis der Kundenaussagen wäre es in Zukunnft wünschenswert mit einem umfangreichen Katalog an Aussagetypen zu arbeiten, der die vielfältigen Aspekte der Customer Journey besser abbildet. Zudem könnte es sich auch als vorteilhaft erweisen den Beobachtungszeitraum so auszudehnen, dass mehr Beobachtungen pro Thema vorliegen. "],["Bisbald.html", "Bis bald!", " Bis bald! Wir leben in einer höchst interessanten Zeit, da die jüngsten technischen Entwicklungen ganz neue Einblicke in die Gedanken der Kunden ermöglichen. Diese spannenden Möglichkeiten, die Machine Learning und Natural Language Processing (NLP) bieten, erfüllen mich mit Begeisterung und Vorfreude auf die Zukunft. Mit den hier vorgestellten Methoden können wir nicht nur das Kundenverhalten besser verstehen, sondern auch tiefere Einblicke in viele andere Bereiche gewinnen. Ob es darum geht, soziale Dynamiken in Online-Communities zu erforschen oder personalisierte Gesundheitslösungen zu entwickeln, die Möglichkeiten sind nahezu grenzenlos. Ich freue mich darauf, diese spannende Reise fortzusetzen und neue Horizonte zu erkunden. Falls Sie weitere Fragen haben oder vertiefende Gespräche wünschen, stehe ich Ihnen gerne zur Verfügung. Bis bald! Sara Schiesberg Kontakt: sara.schiesberg@planumnull.de "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
